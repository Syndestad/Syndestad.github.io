---
title: Extract tables from pdf files with tabulizer
author: synnøve yndestad
date: '2022-03-27'
slug: []
categories:
  - R
tags:
  - webscraping
  - pdf
  - data.frame()
  - tidyverse
  - tabulizer
subtitle: 'Tabulizer, from pdf-url to R data.frame()!'
excerpt: 'Far too often i find myself in a situation where I need to fetch lists of genes, expression data or similar from journal articles, only to to realize that the data is only to be found buried somewhere deep within the supplementary in the form of a giant pdf. (The horror!)  Here is a how to to scrape data from a linked pdf file (by url) using the tabulizer R package.'
---

Far too often i find myself in a situation where I need to fetch lists of genes, expression data or similar from journal articles, only to to realize that the data is only to be found buried somewhere deep within the supplementary in the form of a giant pdf.  
(The horror!)  
If you really want people to use your stuff and cite your work, Please stop doing that. Just add a csv file with the data. Make it accessible. The reason for publishing your data is for others to be able to use it, right? Then stop making it so hard for us to access it! 

Now, after getting this off my chest, here is a how to scrape data from a pdf file (by url) using the tabulizer R package.



Install tabulizer from CRAN.

```{r, eval = FALSE}
if (!require("remotes")) {
    install.packages("remotes")
}
# on 64-bit Windows
remotes::install_github(c("ropensci/tabulizerjars", "ropensci/tabulizer"), INSTALL_opts = "--no-multiarch")
# elsewhere
remotes::install_github(c("ropensci/tabulizerjars", "ropensci/tabulizer"))
```




Load packages.

```{r}
library(tabulizer)
library(tidyverse)
```



Specify the url to where the file is located, and download it. We want [this pdf file]("https://static-content.springer.com/esm/art%3A10.1038%2Fncomms4361/MediaObjects/41467_2014_BFncomms4361_MOESM760_ESM.pdf") 

```{r}
url = "https://static-content.springer.com/esm/art%3A10.1038%2Fncomms4361/MediaObjects/41467_2014_BFncomms4361_MOESM760_ESM.pdf"
download.file(url,"41467_2014_BFncomms4361_MOESM760_ESM.pdf",mode="wb")
```

We want the table named 'Supplementary Table 1: The list of 230 genes designated as “the HRD gene signature"'. The table is located over pages 22-26.


Extract the table from pages 22-26 with extract_tables()  
This produces one list pr page.  

```{r}
HRDlist = extract_tables("41467_2014_BFncomms4361_MOESM760_ESM.pdf", pages = 22:26)

glimpse(HRDlist)
```

Take a look at the content of the first list:

```{r}
head(HRDlist[[1]])
```




Bind the lists together and turn into data frame

```{r}
HRDsignature = do.call(rbind, HRDlist) %>% 
               as.data.frame()
glimpse(HRDsignature)
head(HRDsignature)
```

Some cleanup is required to get correct column names.

```{r}
# Turn first row into column names
HRDsignature[1,]
colnames(HRDsignature) = HRDsignature[1,]

# remove first row
HRDsignature = HRDsignature[-1,]

glimpse(HRDsignature)
head(HRDsignature)
```

Now we have converted a 4 page pdf table into a data.frame ready to use!  
This workflow can now be implemented into scripts, linking directly to the source data for reproducibility.
Happy pdf scraping!  

